{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73vB4dJPwB3o"
   },
   "source": [
    "### Real Time Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2924,
     "status": "ok",
     "timestamp": 1745147580081,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "DsdVxur3JTUg",
    "outputId": "c2a914bc-e56b-4236-ef5f-6887d3871d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/1e/d6/40aa5aead775582ea0cf35870e5a3f16fab4b967f1ad2debe675f673f923/textblob-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Obtaining dependency information for nltk>=3.9 from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9->textblob)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/38/ec/ad2d7de49a600cdb8dd78434a1aeffe28b9d6fc42eb36afab4a27ad23384/regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/624.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/624.3 kB 653.6 kB/s eta 0:00:01\n",
      "   ------ ------------------------------- 102.4/624.3 kB 980.4 kB/s eta 0:00:01\n",
      "   ------ ------------------------------- 102.4/624.3 kB 980.4 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 174.1/624.3 kB 871.5 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 235.5/624.3 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 317.4/624.3 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 399.4/624.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 399.4/624.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- ------------ 419.8/624.3 kB 970.6 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 471.0/624.3 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------ ------- 501.8/624.3 kB 983.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 593.9/624.3 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB 3.8 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.5 MB 1.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.4 MB/s eta 0:00:00\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Installing collected packages: regex, nltk, textblob\n",
      "Successfully installed nltk-3.9.1 regex-2024.11.6 textblob-0.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#  allows users to perform tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, and translation with ease.\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2584,
     "status": "ok",
     "timestamp": 1745147582700,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "mXaMlU3Jy_Bv",
    "outputId": "cd638473-bb4d-43ae-c860-2240018ae022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hadil sghair\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Manly Used for Data PreProcessing (Tokinaation, Stemming ...)\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745147582712,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "__m4_PkS0eIA"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745147582718,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "Uq6U71E1z81Q",
    "outputId": "e3c53f75-38ac-40c4-9a5d-3ae7fb7277a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hadil sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Hadil sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745147962772,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "-dzZ80lL0VaH",
    "outputId": "981eaf07-5f4a-441f-e7cf-f573b7fdaa14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Hadil sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1745147964310,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "XxWlwYaX0ZAy"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob as blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745147965613,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "UUS8MCj-1HNa"
   },
   "outputs": [],
   "source": [
    "tb= blob(\"I love Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745147966413,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "XEDllZTu1NRQ",
    "outputId": "b6cbf199-891f-4d3c-fa27-cc7dbc0bef5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I love Machine Learning\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1745147967315,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "JMCmDE1-1PW3",
    "outputId": "072ca5f2-7230-488c-e98e-d1daa8becfd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TextBlob in module textblob.blob object:\n",
      "\n",
      "class TextBlob(BaseBlob)\n",
      " |  TextBlob(text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n",
      " |\n",
      " |  A general text block, meant for larger bodies of text (esp. those\n",
      " |  containing sentences). Inherits from :class:`BaseBlob <BaseBlob>`.\n",
      " |\n",
      " |  :param str text: A string.\n",
      " |  :param tokenizer: (optional) A tokenizer instance. If ``None``, defaults to\n",
      " |      :class:`WordTokenizer() <textblob.tokenizers.WordTokenizer>`.\n",
      " |  :param np_extractor: (optional) An NPExtractor instance. If ``None``,\n",
      " |      defaults to :class:`FastNPExtractor() <textblob.en.np_extractors.FastNPExtractor>`.\n",
      " |  :param pos_tagger: (optional) A Tagger instance. If ``None``, defaults to\n",
      " |      :class:`NLTKTagger <textblob.en.taggers.NLTKTagger>`.\n",
      " |  :param analyzer: (optional) A sentiment analyzer. If ``None``, defaults to\n",
      " |      :class:`PatternAnalyzer <textblob.en.sentiments.PatternAnalyzer>`.\n",
      " |  :param classifier: (optional) A classifier.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      TextBlob\n",
      " |      BaseBlob\n",
      " |      textblob.mixins.StringlikeMixin\n",
      " |      textblob.mixins.BlobComparableMixin\n",
      " |      textblob.mixins.ComparableMixin\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  sentences = <textblob.decorators.cached_property object>\n",
      " |      Return list of :class:`Sentence <Sentence>` objects.\n",
      " |\n",
      " |  to_json(self, *args, **kwargs)\n",
      " |      Return a json representation (str) of this blob.\n",
      " |      Takes the same arguments as json.dumps.\n",
      " |\n",
      " |      .. versionadded:: 0.5.1\n",
      " |\n",
      " |  words = <textblob.decorators.cached_property object>\n",
      " |      Return a list of word tokens. This excludes punctuation characters.\n",
      " |      If you want to include punctuation characters, access the ``tokens``\n",
      " |      property.\n",
      " |\n",
      " |      :returns: A :class:`WordList <WordList>` of word tokens.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  json\n",
      " |      The json representation of this blob.\n",
      " |\n",
      " |      .. versionchanged:: 0.5.1\n",
      " |          Made ``json`` a property instead of a method to restore backwards\n",
      " |          compatibility that was broken after version 0.4.0.\n",
      " |\n",
      " |  raw_sentences\n",
      " |      List of strings, the raw sentences in the blob.\n",
      " |\n",
      " |  serialized\n",
      " |      Returns a list of each sentence's dict representation.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseBlob:\n",
      " |\n",
      " |  __add__(self, other)\n",
      " |      Concatenates two text objects the same way Python strings are\n",
      " |      concatenated.\n",
      " |\n",
      " |      Arguments:\n",
      " |      - `other`: a string or a text object\n",
      " |\n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |\n",
      " |  __init__(self, text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  classify(self)\n",
      " |      Classify the blob using the blob's ``classifier``.\n",
      " |\n",
      " |  correct(self)\n",
      " |      Attempt to correct the spelling of a blob.\n",
      " |\n",
      " |      .. versionadded:: 0.6.0\n",
      " |\n",
      " |      :rtype: :class:`BaseBlob <BaseBlob>`\n",
      " |\n",
      " |  ngrams(self, n=3)\n",
      " |      Return a list of n-grams (tuples of n successive words) for this\n",
      " |      blob.\n",
      " |\n",
      " |      :rtype: List of :class:`WordLists <WordList>`\n",
      " |\n",
      " |  noun_phrases = <textblob.decorators.cached_property object>\n",
      " |      Returns a list of noun phrases for this blob.\n",
      " |\n",
      " |  np_counts = <textblob.decorators.cached_property object>\n",
      " |      Dictionary of noun phrase frequencies in this text.\n",
      " |\n",
      " |  parse(self, parser=None)\n",
      " |      Parse the text.\n",
      " |\n",
      " |      :param parser: (optional) A parser instance. If ``None``, defaults to\n",
      " |          this blob's default parser.\n",
      " |\n",
      " |      .. versionadded:: 0.6.0\n",
      " |\n",
      " |  polarity = <textblob.decorators.cached_property object>\n",
      " |      Return the polarity score as a float within the range [-1.0, 1.0]\n",
      " |\n",
      " |      :rtype: float\n",
      " |\n",
      " |  pos_tags = <textblob.decorators.cached_property object>\n",
      " |      Returns an list of tuples of the form (word, POS tag).\n",
      " |\n",
      " |      Example:\n",
      " |      ::\n",
      " |\n",
      " |          [\n",
      " |              (\"At\", \"IN\"),\n",
      " |              (\"eight\", \"CD\"),\n",
      " |              (\"o'clock\", \"JJ\"),\n",
      " |              (\"on\", \"IN\"),\n",
      " |              (\"Thursday\", \"NNP\"),\n",
      " |              (\"morning\", \"NN\"),\n",
      " |          ]\n",
      " |\n",
      " |      :rtype: list of tuples\n",
      " |\n",
      " |  sentiment = <textblob.decorators.cached_property object>\n",
      " |      Return a tuple of form (polarity, subjectivity ) where polarity\n",
      " |      is a float within the range [-1.0, 1.0] and subjectivity is a float\n",
      " |      within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is\n",
      " |      very subjective.\n",
      " |\n",
      " |      :rtype: namedtuple of the form ``Sentiment(polarity, subjectivity)``\n",
      " |\n",
      " |  sentiment_assessments = <textblob.decorators.cached_property object>\n",
      " |      Return a tuple of form (polarity, subjectivity, assessments ) where\n",
      " |      polarity is a float within the range [-1.0, 1.0], subjectivity is a\n",
      " |      float within the range [0.0, 1.0] where 0.0 is very objective and 1.0\n",
      " |      is very subjective, and assessments is a list of polarity and\n",
      " |      subjectivity scores for the assessed tokens.\n",
      " |\n",
      " |      :rtype: namedtuple of the form ``Sentiment(polarity, subjectivity,\n",
      " |      assessments)``\n",
      " |\n",
      " |  split(self, sep=None, maxsplit=9223372036854775807)\n",
      " |      Behaves like the built-in str.split() except returns a\n",
      " |      WordList.\n",
      " |\n",
      " |      :rtype: :class:`WordList <WordList>`\n",
      " |\n",
      " |  subjectivity = <textblob.decorators.cached_property object>\n",
      " |      Return the subjectivity score as a float within the range [0.0, 1.0]\n",
      " |      where 0.0 is very objective and 1.0 is very subjective.\n",
      " |\n",
      " |      :rtype: float\n",
      " |\n",
      " |  tags = <textblob.decorators.cached_property object>\n",
      " |      Returns an list of tuples of the form (word, POS tag).\n",
      " |\n",
      " |      Example:\n",
      " |      ::\n",
      " |\n",
      " |          [\n",
      " |              (\"At\", \"IN\"),\n",
      " |              (\"eight\", \"CD\"),\n",
      " |              (\"o'clock\", \"JJ\"),\n",
      " |              (\"on\", \"IN\"),\n",
      " |              (\"Thursday\", \"NNP\"),\n",
      " |              (\"morning\", \"NN\"),\n",
      " |          ]\n",
      " |\n",
      " |      :rtype: list of tuples\n",
      " |\n",
      " |  tokenize(self, tokenizer=None)\n",
      " |      Return a list of tokens, using ``tokenizer``.\n",
      " |\n",
      " |      :param tokenizer: (optional) A tokenizer object. If None, defaults to\n",
      " |          this blob's default tokenizer.\n",
      " |\n",
      " |  tokens = <textblob.decorators.cached_property object>\n",
      " |      Return a list of tokens, using this blob's tokenizer object\n",
      " |      (defaults to :class:`WordTokenizer <textblob.tokenizers.WordTokenizer>`).\n",
      " |\n",
      " |  word_counts = <textblob.decorators.cached_property object>\n",
      " |      Dictionary of word frequencies in this text.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseBlob:\n",
      " |\n",
      " |  analyzer = <textblob.en.sentiments.PatternAnalyzer object>\n",
      " |\n",
      " |  np_extractor = <textblob.en.np_extractors.FastNPExtractor object>\n",
      " |\n",
      " |  parser = <textblob.en.parsers.PatternParser object>\n",
      " |\n",
      " |  pos_tagger = <textblob.en.taggers.NLTKTagger object>\n",
      " |\n",
      " |  tokenizer = <textblob.tokenizers.WordTokenizer object>\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from textblob.mixins.StringlikeMixin:\n",
      " |\n",
      " |  __contains__(self, sub)\n",
      " |      Implements the `in` keyword like a Python string.\n",
      " |\n",
      " |  __getitem__(self, index)\n",
      " |      Returns a  substring. If index is an integer, returns a Python\n",
      " |      string of a single character. If a range is given, e.g. `blob[3:5]`,\n",
      " |      a new instance of the class is returned.\n",
      " |\n",
      " |  __iter__(self)\n",
      " |      Makes the object iterable as if it were a string,\n",
      " |      iterating through the raw string's characters.\n",
      " |\n",
      " |  __len__(self)\n",
      " |      Returns the length of the raw text.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Returns a string representation for debugging.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Returns a string representation used in print statements\n",
      " |      or str(my_blob).\n",
      " |\n",
      " |  ends_with = endswith(self, suffix, start=0, end=9223372036854775807)\n",
      " |\n",
      " |  endswith(self, suffix, start=0, end=9223372036854775807)\n",
      " |      Returns True if the blob ends with the given suffix.\n",
      " |\n",
      " |  find(self, sub, start=0, end=9223372036854775807)\n",
      " |      Behaves like the built-in str.find() method. Returns an integer,\n",
      " |      the index of the first occurrence of the substring argument sub in the\n",
      " |      sub-string given by [start:end].\n",
      " |\n",
      " |  format(self, *args, **kwargs)\n",
      " |      Perform a string formatting operation, like the built-in\n",
      " |      `str.format(*args, **kwargs)`. Returns a blob object.\n",
      " |\n",
      " |  index(self, sub, start=0, end=9223372036854775807)\n",
      " |      Like blob.find() but raise ValueError when the substring\n",
      " |      is not found.\n",
      " |\n",
      " |  join(self, iterable)\n",
      " |      Behaves like the built-in `str.join(iterable)` method, except\n",
      " |      returns a blob object.\n",
      " |\n",
      " |      Returns a blob which is the concatenation of the strings or blobs\n",
      " |      in the iterable.\n",
      " |\n",
      " |  lower(self)\n",
      " |      Like str.lower(), returns new object with all lower-cased characters.\n",
      " |\n",
      " |  replace(self, old, new, count=9223372036854775807)\n",
      " |      Return a new blob object with all the occurence of `old` replaced\n",
      " |      by `new`.\n",
      " |\n",
      " |  rfind(self, sub, start=0, end=9223372036854775807)\n",
      " |      Behaves like the built-in str.rfind() method. Returns an integer,\n",
      " |      the index of he last (right-most) occurence of the substring argument\n",
      " |      sub in the sub-sequence given by [start:end].\n",
      " |\n",
      " |  rindex(self, sub, start=0, end=9223372036854775807)\n",
      " |      Like blob.rfind() but raise ValueError when substring is not\n",
      " |      found.\n",
      " |\n",
      " |  starts_with = startswith(self, prefix, start=0, end=9223372036854775807)\n",
      " |\n",
      " |  startswith(self, prefix, start=0, end=9223372036854775807)\n",
      " |      Returns True if the blob starts with the given prefix.\n",
      " |\n",
      " |  strip(self, chars=None)\n",
      " |      Behaves like the built-in str.strip([chars]) method. Returns\n",
      " |      an object with leading and trailing whitespace removed.\n",
      " |\n",
      " |  title(self)\n",
      " |      Returns a blob object with the text in title-case.\n",
      " |\n",
      " |  upper(self)\n",
      " |      Like str.upper(), returns new object with all upper-cased characters.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from textblob.mixins.StringlikeMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from textblob.mixins.ComparableMixin:\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Hadil sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1745147970428,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "kEZF1I7J1gqN",
    "outputId": "d5277698-6f43-484a-f11d-92e6e5a6bd9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('Machine', 'NNP'), ('Learning', 'NNP')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1745148186022,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "HlbcMgsU8ALv",
    "outputId": "6bff929e-5bfa-4289-d8a5-0ebe195eb632"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Hadil\n",
      "[nltk_data]     sghair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1745148372363,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "x96_c7vO7NId",
    "outputId": "86b8fe18-2159-43ee-eaa9-96a275c21491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['machine learning'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Help understand the Structure of a Sentence\n",
    "tb.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745148449565,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "r-OjSrbK8uBk",
    "outputId": "b3376911-7e86-4db3-d779-7e8e64717602"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745148483048,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "lMAvNAY39DU8"
   },
   "outputs": [],
   "source": [
    "tb= blob(\"I hate Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745148490635,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "hfZgkRhu9JxN",
    "outputId": "0e31d057-634c-4692-d565-f4e3e2bcdeb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.8, subjectivity=0.9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAPRlboA-dPr"
   },
   "source": [
    "#### Real Time Voice Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5634,
     "status": "ok",
     "timestamp": 1745149223593,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "oxgm9KDe-iAv",
    "outputId": "c817e1e9-08e5-4c87-f1ec-7a9832d5eaf2"
   },
   "outputs": [],
   "source": [
    "! pip install SpeechRecognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10016,
     "status": "ok",
     "timestamp": 1745149398020,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "F7ukP_KKAOeL",
    "outputId": "5cf18a59-6e80-4fce-ff45-c37c48733f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyAudio\n",
      "  Obtaining dependency information for PyAudio from https://files.pythonhosted.org/packages/b0/6a/d25812e5f79f06285767ec607b39149d02aa3b31d50c2269768f48768930/PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Using cached PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: PyAudio\n",
      "Successfully installed PyAudio-0.2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745149401566,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "oy0UtvmP_wAS"
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745149509306,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "8TN3IsJ-AQSC"
   },
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 809,
     "status": "error",
     "timestamp": 1745149515882,
     "user": {
      "displayName": "Hadil Sghair",
      "userId": "10692275205745332160"
     },
     "user_tz": -60
    },
    "id": "HPDSvagiAuBa",
    "outputId": "723b7e48-a511-4c1f-c6a2-1667c0080fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something...\n",
      "Sorry... Try again\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    print('Say Something...')\n",
    "    audio = r.listen(source, timeout=2)\n",
    "    try:\n",
    "        text = r.recognize_google(audio) # For Audio Transcript\n",
    "        tb = blob(text)\n",
    "        print(text)\n",
    "        print(tb.sentiment)\n",
    "    except:\n",
    "        print('Sorry... Try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vL9NF85A3vm"
   },
   "outputs": [],
   "source": [
    "# This will help make the code more interactive\n",
    "# and allow the user to speak multiple times \n",
    "# A phone call in this case \n",
    "iter_num = 10\n",
    "index = 0\n",
    "while(index<iter_num):\n",
    "    with sr.Microphone() as source:\n",
    "        print()\n",
    "        print('Say Something...')\n",
    "        audio = r.listen(source, timeout=3)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            tb = blob(text)\n",
    "            print(text)\n",
    "            print(tb.sentiment)\n",
    "        except:\n",
    "            print('Sorry... Try again')\n",
    "        index = index + 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNwxUS9RN+A+m+xfMoVDQBH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
